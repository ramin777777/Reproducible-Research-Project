{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to add the one-hot encoding columns to the dataframe, we use the concatfunction. axis = 1 is used to add the columns.\n",
    "df = pd.concat([df,cols_new_cat], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2eb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_all_cat=list(cols_new_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols_all_cat].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f53289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this process we created 62 features.We separated the features to the following:\n",
    "print('Total number of features:', len(cols_all_cat+cols_num))\n",
    "print('Numerical Features:',len(cols_num))\n",
    "print('Categorical Features:',len(cols_all_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the empty cells\n",
    "df[cols_num+cols_all_cat].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_input = cols_num + cols_all_cat\n",
    "df_data = df[cols_input + ['OUTPUT_LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ced950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s shuffle the samples using sample in case there was some order. \n",
    "#Here n is the number of samples. \n",
    "#random_state is just specified so the project is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d37aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the samples\n",
    "df_data = df_data.sample(n = len(df_data), random_state = 42)\n",
    "df_data = df_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05171819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use \"sample\" again to extract 30% of the data to be used for validation and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0980405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_test=df_data.sample(frac=0.30,random_state=42)\n",
    "print('Split size: %.3f'%(len(df_valid_test)/len(df_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c350295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we split into test and validation using 50% fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_valid_test.sample(frac = 0.5, random_state = 42)\n",
    "df_valid = df_valid_test.drop(df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf63230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the rest of the data as training data\n",
    "df_train_all=df_data.drop(df_valid_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s check what percent of our groups are likely to subscribe to a term deposit.\n",
    "#All three groups would have similar prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the prevalence of each \n",
    "print('Test prevalence(n = %d):%.3f'%(len(df_test),calc_prevalence(df_test.OUTPUT_LABEL.values)))\n",
    "print('Valid prevalence(n = %d):%.3f'%(len(df_valid),calc_prevalence(df_valid.OUTPUT_LABEL.values)))\n",
    "print('Train all prevalence(n = %d):%.3f'%(len(df_train_all), calc_prevalence(df_train_all.OUTPUT_LABEL.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we have a few thousand positive cases, let’s use the sub-sample approach.\n",
    "#we created a balanced training, validatoin and test data set that has 50% positive and 50% negative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
